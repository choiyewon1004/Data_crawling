# -*- coding: utf-8 -*-
"""2.crawling_detail_info.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aLyvaffY58LZ-5YU413cyGRERBKGc5TB

## 1. 정보가 일정하게 있다고 가정
"""

find_url = "https://www.musinsa.com/mz/streetsnap?_mon="

from bs4 import BeautifulSoup
import requests
import pandas as pd
from tqdm.auto import tqdm

result_href =[]
result_png =[]
result_pictime=[]
result_loc =[]
result_style=[]
result_mon =[]

result_item=[]

def geturl(url):
    response = requests.get(url)
    html = BeautifulSoup(response.content, 'html.parser')
    return html

'''
for i in range(1,13):
  url = find_url+str(i)    
  html = geturl(url).find_all("div",{"class":"articleImg"})
  for board in tqdm(html, leave= True):
    move_url = "https://www.musinsa.com"+board.find('a')['href']
    result_href.append(move_url)
    find_info = geturl(move_url).select('table>tbody>tr>td>span')
    result_pictime.append(find_info[1].get_text())
    result_loc.append( find_info[3].get_text())
    result_style.append(find_info[5].get_text())

    
    find_list = board.select('img')
    find_pictime = geturl(move_url).select('table>tbody>tr>td>span')[1].get_text()
    result_pictime.append(find_pictime)
    for j in find_list:
        result_place.append(j['alt'].split('_')[0])
        result_png.append(j['src'])
    '''
# final_df = pd.DataFrame(zip(result_href, result_png, result_pictime, result_place), columns=['href','png','pictime','place'])

## 아이템 테스트

'''
move_url = "https://www.musinsa.com/mz/streetsnap/view/88103?_mon=1"
html = geturl(move_url)


find_info = html.select('table>tbody>tr>td>span')
result_pictime.append(find_info[1].get_text())
result_loc.append( find_info[3].get_text())
result_style.append(find_info[5].get_text())
result_png.append(html.find("div",{"class": "snapImg"}).find('a')['href'])

check_item =[]
find_clothes = html.find_all("p",{"class":"title"})
size = len(find_clothes)

for i in range(size):
  test = str(find_clothes[i].get_text().replace('\t','')[1:])
  check_item.append(test)
result_item.append(check_item)
'''

from bs4 import BeautifulSoup
import requests
import pandas as pd
from tqdm.auto import tqdm


result_href =[]
result_png =[]
result_pictime=[]
result_loc =[]
result_style=[]
result_mon =[]

result_item=[]
find_url = "https://www.musinsa.com/mz/streetsnap?_mon="


def geturl(url):
    response = requests.get(url)
    html = BeautifulSoup(response.content, 'html.parser')
    return html


for i in range(10 ,11):
  url = find_url+str(i)    
  html = geturl(url).find_all("div",{"class":"articleImg"})
  for board in tqdm(html, leave= True):
    move_url = "https://www.musinsa.com"+board.find('a')['href']
    result_href.append(move_url)

    move_html = geturl(move_url)
    find_info = move_html.select('table>tbody>tr>td>span')
    result_pictime.append(find_info[1].get_text())
    result_loc.append( find_info[3].get_text())
    result_style.append(find_info[5].get_text())
    result_png.append(move_html.find("div",{"class": "snapImg"}).find('a')['href'])

    check_item =[]
    find_clothes = move_html.find_all("p",{"class":"title"})
    size = len(find_clothes)

    for i in range(size):
      test = str(find_clothes[i].get_text().replace('\t','')[1:])
      check_item.append(test)

    result_item.append(check_item)

final_df = pd.DataFrame(zip(result_href, result_png, result_pictime, result_loc, result_item), columns=['href','png','pictime','place', 'item'])

"""## 2. 정보가 다를 수도 있다고 가정"""

move_url = "https://www.musinsa.com/mz/streetsnap/view/85916?_mon=10"

result_href.append(move_url)

move_html = geturl(move_url)
find_info = move_html.select('table>tbody>tr')
for i in find_info:
  find_info_title = i.find("span")
  if find_info_title.get_text() == "촬영일":
    #print("촬영일 : ",i.select_one("tr>td>span").get_text() ) /
    result_pictime.append(i.select_one("tr>td>span").get_text())
  elif find_info_title.get_text() == "촬영지역":
    #print("촬영지역 : ",i.select_one("tr>td>span").get_text()) 
    result_loc.append(i.select_one("tr>td>span").get_text()) 
  elif find_info_title.get_text() == "스타일":
    #print("스타일 : ",i.select_one("tr>td>span").get_text()) 
    result_style.append(i.select_one("tr>td>span").get_text())

from bs4 import BeautifulSoup
import requests
import pandas as pd
from tqdm.auto import tqdm


result_href =[]
result_png =[]
result_pictime=[]
result_loc =[]
result_style=[]
result_mon =[]

result_item=[]

find_url = "https://www.musinsa.com/mz/streetsnap?_mon="


def geturl(url):
    response = requests.get(url)
    html = BeautifulSoup(response.content, 'html.parser')
    return html


for i in range(10 ,11):
  url = find_url+str(i)    
  html = geturl(url).find_all("div",{"class":"articleImg"})
  for board in tqdm(html, leave= True):
    move_url = "https://www.musinsa.com"+board.find('a')['href']
    result_href.append(move_url)

    move_html = geturl(move_url)
    find_info = move_html.select('table>tbody>tr')
    for i in find_info:
      find_info_title = i.find("span")
      if find_info_title.get_text() == "촬영일":
        #print("촬영일 : ",i.select_one("tr>td>span").get_text() ) /
        result_pictime.append(i.select_one("tr>td>span").get_text())
      elif find_info_title.get_text() == "촬영지역":
        #print("촬영지역 : ",i.select_one("tr>td>span").get_text()) 
        result_loc.append(i.select_one("tr>td>span").get_text()) 
      elif find_info_title.get_text() == "스타일":
        #print("스타일 : ",i.select_one("tr>td>span").get_text()) 
        result_style.append(i.select_one("tr>td>span").get_text())

    result_png.append(move_html.find("div",{"class": "snapImg"}).find('a')['href'])

    check_item =[]
    find_clothes = move_html.find_all("p",{"class":"title"})
    size = len(find_clothes)

    for i in range(size):
      test = str(find_clothes[i].get_text().replace('\t','')[1:])
      check_item.append(test)

    result_item.append(check_item)

final_df = pd.DataFrame(zip(result_href, result_png, result_pictime, result_loc,result_style, result_item), columns=['href','png','pictime','loc', 'style','item'])

final_df.to_csv('2.result.csv')

"""## 3. 상세 옷 상세 정보 """

from bs4 import BeautifulSoup
import requests
import pandas as pd
from tqdm.auto import tqdm


result_href =[]
result_png =[]
result_pictime=[]
result_loc =[]
result_style=[]
result_mon =[]

result_item=[]

find_url = "https://www.musinsa.com/mz/streetsnap?_mon="


def geturl(url):
    response = requests.get(url)
    html = BeautifulSoup(response.content, 'html.parser')
    return html


for i in range(10 ,11):
  url = find_url+str(i)    
  html = geturl(url).find_all("div",{"class":"articleImg"})
  for board in tqdm(html, leave= True):
    move_url = "https://www.musinsa.com"+board.find('a')['href']
    result_href.append(move_url)

    move_html = geturl(move_url)
    find_info = move_html.select('table>tbody>tr')
    for i in find_info:
      find_info_title = i.find("span")
      if find_info_title.get_text() == "촬영일":
        #print("촬영일 : ",i.select_one("tr>td>span").get_text() ) /
        result_pictime.append(i.select_one("tr>td>span").get_text())
      elif find_info_title.get_text() == "촬영지역":
        #print("촬영지역 : ",i.select_one("tr>td>span").get_text()) 
        result_loc.append(i.select_one("tr>td>span").get_text()) 
      elif find_info_title.get_text() == "스타일":
        #print("스타일 : ",i.select_one("tr>td>span").get_text()) 
        result_style.append(i.select_one("tr>td>span").get_text())

    result_png.append(move_html.find("div",{"class": "snapImg"}).find('a')['href'])

    check_item =[]
    find_clothes = move_html.find("ul", {"class":"styleItem-list"}).find_all("div",{"class" : "itemInfo"})
    for i in find_clothes:
      res_dic={}
      style_list=[]
      find_clothes_title = i.find("p",{"class" : "title"}).get_text().replace("\t","")[1:]
      find_clothes_style = i.find_all('span')
      for j in find_clothes_style:
          style_list.append(j.get_text())
      res_dic['item_title'] = find_clothes_title
      res_dic['item_style'] = style_list
      check_item.append(res_dic)

    result_item.append(check_item)
    
final_df = pd.DataFrame(zip(result_href, result_png, result_pictime, result_loc,result_style, result_item), columns=['href','png','pictime','loc', 'style','item'])   
final_df.to_csv('3,result.csv')

move_url = "https://www.musinsa.com/mz/streetsnap/view/88103?_mon=1"
move_html = geturl(move_url)

check_item =[]
find_clothes = move_html.find("ul", {"class":"styleItem-list"}).find_all("div",{"class" : "itemImg"})


for i in find_clothes:
  res_dic={}
  style_list=[]
  find_clothes_title = i.find("p",{"class" : "title"}).get_text().replace("\t","")[1:]
  find_clothes_style = i.find_all('span')
  for j in find_clothes_style:
      style_list.append(j.get_text())
  res_dic['item_title'] = find_clothes_title
  res_dic['item_img'] = i.find('a')['href']
  res_dic['item_style'] = style_list
  
  check_item.append(res_dic)

check_item

find_clothes = move_html.find("ul", {"class":"styleItem-list"}).find_all("div",{"class" : "itemInfo"})
for i in find_clothes:
  res_dic={}
  style_list=[]
  find_clothes_title = i.find("p",{"class" : "title"}).get_text().replace("\t","")[1:]
  find_clothes_style = i.find_all('span')
  for j in find_clothes_style:
      style_list.append(j.get_text())
  res_dic['item_title'] = find_clothes_title
  res_dic['item_style'] = style_list
 
  print(res_dic)
  print()
  print()
  print()
  print()

||